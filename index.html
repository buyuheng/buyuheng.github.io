<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Yuheng Bu's Homepage</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Yuheng Bu</div>
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
<div class="menu-item"><a href="Yuheng_CV.pdf">CV</a></div>
<div class="menu-item"><a href="publications.html">Publications</a></div>
<div class="menu-item"><a href="teaching.html">Teaching</a></div>
<div class="menu-item"><a href="https://scholar.google.com/citations?user=1jPQEVMAAAAJ&hl=en">Google&nbsp;Scholar</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Yuheng Bu's Homepage</h1>
</div>
<table class="imgtable"><tr><td>
<img src="./bu.JPG" alt="photo" width="235px" height="240px" />&nbsp;</td>
<td align="left"><h1>Yuheng Bu</h1>
<p>Assistant Professor <br />
<a href="https://www.ece.ufl.edu/">Department of Electrical &amp; Computer Engineering (ECE)</a> <br />
<a href="https://www.eng.ufl.edu/">Herbert Wertheim College of Engineering</a><br />
<a href="https://www.ufl.edu/">University of Florida</a></p>
<h2>Contact Information</h2>
<p>Email: buyuheng [at] {ufl} [dot] edu  <br />
<a href="https://scholar.google.com/citations?user=1jPQEVMAAAAJ&amp;hl=en">Google Scholar</a><br />
<a href="https://dblp.org/pers/hd/b/Bu:Yuheng">DBLP</a><br /></p>
</td></tr></table>
<h2>Biography</h2>
<p>I am an Assistant Professor in the <a href="https://www.ece.ufl.edu/">Department of Electrical &amp; Computer Engineering (ECE)</a>  at <a href="https://www.ufl.edu/">University of Florida</a>. </p>
<p>Before joining the University of Florida, I was a postdoctoral research associate at the <a href="https://www.rle.mit.edu/">Research Laboratory of Electronics</a> and <a href="https://idss.mit.edu/">Institute for Data, Systems, and Society (IDSS)</a>, <a href="https://www.mit.edu/">Massachusetts Institute of Technology (MIT)</a>. 
I received my Ph.D. degree at the <a href="https://csl.illinois.edu/">Coordinated Science Laboratory</a> and the <a href="https://ece.illinois.edu/">Department of Electrical and Computer Engineering</a>, <a href="https://illinois.edu/">University of Illinois at Urbana-Champaign (UIUC)</a> in 2019. Before that, I received a B.S. degree (with honors) in <a href="https://www.ee.tsinghua.edu.cn/en/">Electronic Engineering</a> from <a href="https://www.tsinghua.edu.cn/en/index.htm">Tsinghua University</a> in 2014. </p>
<h2>Research</h2>
<p>My research interests lie in the intersection of <b>machine learning</b>, <b>information theory</b> and <b>signal processing</b>. I leverage the tools from <i>information theory</i> and <i>signal processing</i> to develop theoretically justified learning algorithms for diverse applications, including <a href="https://arxiv.org/pdf/2302.08077.pdf"><i>fair machine learning</i></a>, <a href="https://arxiv.org/pdf/2212.07359.pdf"><i>uncertainty quantification</i></a>, <a href="Conference/AAAI_2020.pdf"><i>model compression</i></a>, and <a href="Journal/Linear_test.pdf"><i>anomaly detection</i></a>.  </p>
<p>More broadly, the primary goal of my research is to lay information-theoretic foundations for trustworthy learning algorithms, particularly with generalization, fairness, and privacy guarantees.</p>
<h2>To Prospective Students</h2>
<p>PhD candidates: <b>Self-motivated</b> students with strong backgrounds in <b>probability</b>, <b>statistics</b>, <b>machine learning</b>, and <b>information theory</b> are welcome to reach out.  You should be comfortable with writing and reading proofs and learning challenging new mathematical concepts; in other words, a decent <a href="https://terrytao.wordpress.com/career-advice/theres-more-to-mathematics-than-rigour-and-proofs/">mathematical maturity</a> is required. </p>
<p>Please send me an email with the subject &ldquo;Prospective Ph.D. Student&rdquo; attached with your academic CV and undergraduate/graduate transcripts.</p>
<h2>Selected Publications</h2>
<ul>
<li><p><b>Y. Bu</b>*, G. Aminian*,  L. Toni, M. R. D. Rodrigues, G. W. Wornell. <a href="https://proceedings.mlr.press/v151/bu22a.html">&ldquo;Characterizing and Understanding the Generalization Error of Transfer Learning with Gibbs Algorithm,&rdquo;</a> (* equal contribution), International Conference on Artificial Intelligence and Statistics (AISTATS), Mar. 2022. </p>
</li>
<li><p>G. Aminian*, <b>Y. Bu</b>*, L. Toni, M. R. D. Rodrigues, G. W. Wornell. <a href="https://papers.nips.cc/paper/2021/hash/445e24b5f22cacb9d51a837c10e91a3f-Abstract.html">&ldquo;An Exact Characterization of the Generalization Error for the Gibbs Algorithm,&rdquo;</a> (* equal contribution), Conference on Neural Information Processing Systems (NeurIPS), 2021. </p>
</li>
<li><p><b>Y. Bu</b>*, J. K. Lee*, D. Rajan, P. Sattigeri, R. Panda, S. Das, G. W. Wornell. <a href="http://proceedings.mlr.press/v139/lee21b.html">&ldquo;Fair Selective
Classification via Sufficiency,&rdquo;</a> (* equal contribution), International Conference on Machine Learning (ICML), Jul. 2021. <b>(Long Talk, Top 3%)</b></p>
</li>
<li><p><b>Y. Bu</b>, S. Zou, V. V. Veeravalli. <a href="Journal/Gen_bound.pdf">&ldquo;Tightening Mutual Information Based Bounds on Generalization Error,&rdquo;</a> IEEE Journal on Selected Areas in Information Theory, vol. 1, pp. 121 - 130, May 2020.</p>
</li>
<li><p><b>Y. Bu</b>, S. Zou, V. V. Veeravalli. <a href="Journal/Linear_test.pdf">&ldquo;Linear-Complexity Exponentially-Consistent Tests for Universal Outlying Sequence Detection,&rdquo;</a> IEEE Transactions on Signal Processing, vol. 67, no. 8, pp. 2115-2128, Apr. 2019. </p>
</li>
<li><p><b>Y. Bu</b>*, S. Zou*, Y. Liang, V. V. Veeravalli. <a href="Journal/Minimax_KL.pdf">&ldquo;Estimation of KL Divergence: Optimal Minimax Rate,&rdquo;</a> (*equal contribution), IEEE Transactions on Information Theory, vol. 64, no. 4, pp. 2648-2674, Apr. 2018. </p>
</li>
</ul>
<h2>News</h2>
<ul>
<li><p>Apr 2023, our paper, <a href="https://proceedings.mlr.press/v202/shen23b.html">&ldquo;On Balancing Bias and Variance in Unsupervised Multi-Source-Free Domain Adaptation,&rdquo;</a> has been accepted by ICML 2023 (acceptance rate: 28%). I'll see you in Hawaii!</p>
</li>
<li><p>Apr 2023, two papers, &ldquo;On the Generalization Error of Meta Learning for the Gibbs Algorithm&rdquo; and &ldquo;A Bilateral Bound on the Mean Squared Error for Estimation in Model Mismatch,&rdquo; have been accepted by ISIT 2023.</p>
</li>
<li><p>Feb 2023, my collaborators and I were interviewed with <a href="https://news.mit.edu/2023/improving-machine-learning-models-reliability-0213"><b>MIT News</b></a> for our recent AAAI publication <a href="https://ojs.aaai.org/index.php/AAAI/article/view/26167">&ldquo;Post-hoc Uncertainty Learning using a Dirichlet Meta-Model.&rdquo;</a> Check out  <a href="https://news.mit.edu/2023/improving-machine-learning-models-reliability-0213"><b>here</b></a>!</p>
</li>
<li><p>Feb 2023, I gave a talk on &ldquo;Characterizing the generalization error of Gibbs algorithms using information measures&rdquo; at <a href="https://ita.ucsd.edu/">Information Theory and Applications Workshop</a>, ITA 2023, San Diego.</p>
</li>
<li><p>Jan 2023, our paper, &ldquo;Adaptive Sequential Machine Learning,&rdquo; has been selected as the winner of the 16th <b>Abraham Wald Prize</b> in Sequential Analysis!</p>
</li>
<li><p>Jan 2023, I have co-organized the <a href="https://meyn.ece.ufl.edu/c3/6th-workshop-on-cognition-control/"><b>6th Annual Workshop on Cognition &amp; Control</b></a> together with <a href="https://meyn.ece.ufl.edu/about/">Prof. Sean Meyn</a>, <a href="https://saxena.ece.ufl.edu/">Prof. Shreya Saxena</a> at UF Reitz Union. Talks include topics such as reinforcement learning, accelerated optimization, information theory, brain-machine interface systems, and much more!</p>
</li>
<li><p>Jan 2023, I gave a virtual presentation &ldquo;From Sensitivity-constrained Information Bottleneck to Fair Selective Prediction&rdquo; at <a href="https://ims.nus.edu.sg/events/information-theory-and-data-science-workshop/">Information Theory and Data Science Workshop</a> organized by National University of Singapore.</p>
</li>
<li><p>Jan 2023, our paper, &ldquo;Reliable Gradient-free and Likelihood-free Prompt Tuning,&rdquo; has been accepted by Findings of EACL 2023!</p>
</li>
<li><p>Jan 2023, our paper, &ldquo;How Does Pseudo-Labeling Affect the Generalization Error of the Semi-Supervised  Gibbs Algorithm?&rdquo; has been accepted by AISTATS 2023 (acceptance rate: 29%)!</p>
</li>
<li><p>Nov 2022, our paper, &ldquo;Post-hoc Uncertainty Learning using a Dirichlet Meta-Model,&rdquo; has been accepted by AAAI 2023 (acceptance rate: 19%)! </p>
</li>
<li><p>Aug 2022, our paper, &ldquo;Exploiting Temporal Structures of Cyclostationary Signals for Data-Driven Single-Channel Source Separation,&rdquo; has been awarded as <a href="https://2022.ieeemlsp.org/2022/08/25/best-student-paper-contest-results/"><b>Best Student Paper</b></a> by IEEE MLSP 2022.</p>
</li>
<li><p>Aug 2022, <a href="https://pronics2004.github.io/">Dr. Prasanna Sattigeri</a> and I are serving as Guest Editors for the Entropy Special Issue <a href="https://www.mdpi.com/journal/entropy/special_issues/Fairness_Mach_Learn"><b>&ldquo;Fairness in Machine Learning: Information Theoretic Perspectives.&rdquo;</b></a> We warmly invite you to contribute an <b>article or extended conference paper</b> for this Special Issue.</p>
</li>
<li><p>Aug 2022, our paper, &ldquo;Data-Driven Blind Synchronization and Interference Rejection for Digital Communication Signals,&rdquo; has been accepted by GLOBECOM 2022.</p>
</li>
<li><p>Jul 2022, my collaborators and I were interviewed with <a href="https://news.mit.edu/2022/fairness-accuracy-ai-models-0720"><b>MIT News</b></a> for our recent ICML publication <a href="https://proceedings.mlr.press/v162/shah22a.html">&ldquo;Selective Regression under Fairness Criteria.&rdquo;</a> Check out  <a href="https://news.mit.edu/2022/fairness-accuracy-ai-models-0720"><b>here</b></a>!</p>
</li>
<li><p>Jun 2022, our paper, &ldquo;Exploiting Temporal Structures of Cyclostationary Signals for Data-Driven Single-Channel Source Separation,&rdquo; has been accepted by IEEE MLSP 2022.</p>
</li>
<li><p>May 2022, our paper, &ldquo;Selective Regression under Fairness Criteria,&rdquo; has been accepted by ICML 2022 (acceptance rate: 22%)! </p>
</li>
<li><p>Apr 2022, our paper, &ldquo;Tighter Expected Generalization Error Bounds via Convexity of Information Measures,&rdquo; has been accepted by ISIT 2022.</p>
</li>
<li><p>Jan 2022, our paper, &ldquo;A Maximal Correlation Approach to Imposing Fairness in Machine Learning,&rdquo; has been accepted by ICASSP 2022.</p>
</li>
<li><p>Jan 2022, our paper, &ldquo;Characterizing and Understanding the Generalization Error of Transfer Learning with Gibbs Algorithm,&rdquo; has been accepted by AISTATS 2022 (acceptance rate: 29%)!</p>
</li>
<li><p>Sept 2021, our paper, &ldquo;An Exact Characterization of the Generalization Error for the Gibbs Algorithm,&rdquo; has been accepted by NeurIPS 2021 (acceptance rate: 26%)!</p>
</li>
<li><p>Sept 2021, our paper, &ldquo;Population Risk Improvement with Model Compression: An Information-Theoretic Approach,&rdquo; has been published in Entropy as part of the Special Issue Information Theory and Machine Learning.</p>
</li>
<li><p>May 2021, our paper, &ldquo;Fair Selective Classification via Sufficiency,&rdquo; has been accepted by ICML 2021 (<b>Long Talk: Top 3%</b>)!</p>
</li>
</ul>
<div id="footer">
<div id="footer-text">
Page generated 2023-07-09 17:48:38 Eastern Daylight Time, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
